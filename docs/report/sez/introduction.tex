\section{Introduction}
At the beginning we provide a short description of the problem. Next, we talk about the implemented method to find the gradient and the activation function used in the experiments. At the end, we give some information about the used regularization method.
\subsection{Neural network}
Let \textit{M} be a neural network with a specific topology. The main goal of this project was to learn and develop three different optimization methods for \textit{M}. We exploit:
\begin{itemize}
	\item Standard momentum descent approach;
	\item Algorithm of the class of limited-memory quasi-Newton methods for L2 regularization;
	\item Algorithm of the class of bundle methods for L1 regularization;
\end{itemize}
\subsection{Backpropagation}
The backpropagation algorithm can be divided in two part:
\begin{itemize}
	\item Compute the network's gradient;
	\item Use the knowledge of the gradient to do the next step depending on the optimizer chosen;
\end{itemize}
\subsection{Activation function}
\label{activationFunction}
The activation function of a node defines the output of that node given an input or set of inputs. 
Properties of this function can be:
\begin{itemize}
	\item Nonlinear;
	\item Range;
	\item Continuously differentiable;
	\item Monotonic;
	\item Smooth functions with a monotonic derivative;
	\item Approximates identity near the origin;
\end{itemize}

For the aim of our project, we chose to use two different activation function:
\begin{itemize}
	\label{sigmoid}
	\item Sigmoid (or standard logistic function):
	\begin{itemize}
		\item It is defined between (0,1); 		
			\begin{align*}
			&f(x) = \sigma(x) = \frac{1}{1 + e^{-x}} \\
			&f'(x) = \sigma'(x) = f(x)(1 - f(x)),
			\end{align*} 
	\end{itemize}
	\item TanH;
	\label{tanH}
	\begin{itemize}
		\item It is defined between (-1,1); 		
		\begin{align*}
		&f(x) = \sigma(x) = \frac{e^{x}-e^{-x}}{e^{x} + e^{-x}} \\
		&f'(x) = \sigma'(x) = 1 - f(x)^{2},
		\end{align*} 
	\end{itemize}
\end{itemize}
Since the purpose of
\subsection{Loss Function}
\label{Loss:Mse}
The \textit{Loss Function} is a function used to evaluate the performance of a model, given the $h(w)$ vector compute by the network and the desired vector values $\widehat{y}$ measures the average of the squares of the errors. There are several \textit{Loss Function} used in machine learning algorithms but we are going to focus on the \textit{Mean Squared Error} (MSE). This is obtained by the formula: 	
\begin{equation}
MSE = \frac{1}{n} \sum_{i=1}^n (h(w) - \widehat{y})_{i}^2
\end{equation}
where $n$ represents the number of sample input data we passed into in the model. 
The \textit{Loss Function} can be represented as a composition of the Euclidean norm and the quadratic function
\begin{equation}
MSE = \frac{1}{n} \parallel h(w) - \widehat{y} \parallel_{2}^2  
\end{equation}

Moreover the train phase of a supervised machine learning algorithm can be seen as an optimization (in our case minimization) of the \textit{Loss Function} by altering the weights of the network $w$.   
Since the purpose of neural networks is to build models that fits data, we want to minimize the \textit{Loss Function} in order to have good prediction on unseen data. This minimization process is done through optimization algorithms but to minimize the \textit{Loss Function} it must have certain properties.	

\subsubsection{Loss Function properties}
\label{LF:Properties}
In an optimization problem given $X$ any set and $f: X \rightarrow \mathbb{R}$ any function we want
\begin{equation}
(P) \quad f_{*} = min \{f(x) : x \in X\}
\end{equation}
where X is the feasible region, f is the objective function and $v(P) = f_{*}$ is the optimal value. In our case $X \subseteq \mathbb{R}^{n}$ and we want to be sure that exist an optimal solution.

So we want to find any optimal solution: $x_{*} \in X  \textnormal{ such that } f(x_{*}) = f_{*}$ but this can be impossible for many reasons. For the \textit{Weierstrass} theorem to ensure that our function has an optimal solution we need that $X \subseteq \mathbb{R}^{n}$ is compact and $f$ is continuous (or lower semi-continuous) and differentiable. 

\begin{itemize}
	\item \textbf{Continuity}: A function $f$ is \textit{ Lipschitz continuous} on its domain $S$ if $\exists L>0$ such that
	\begin{equation}
	|f(x)-f(y)| \leq L\parallel x-y\parallel \quad \forall x,y \in S,  
	\end{equation} 
	more formally a function is  \textit{Locally Lipschitz Continuous} at $x$ if $\exists \varepsilon >0 \textnormal{ s.t } S \in \beta(x,\varepsilon) $
	and it is \textit{Global Lipschitz Continuous} if $f$ is \textit{Locally Lipschitz Continuous} on all the space S, in our case $R^n$.
	Since neural networks are a series of function composition: 
	\begin{equation}
	h(x) = \phi_{k}(b_{k} + \sum_{j}w_{kj} \phi_{j}(b_{j} + \sum_{i}w_{ji}x))
	\end{equation}
	where $x$ is the input and $\phi_{i}$ is an activation function. MSE is a composition of the Euclidean norm that is quadratic, and the output function, so the composition between the used activation functions. To ensure it's Lipschitz continuity we have to restrict its domain to a bounded one, since we initialize the weights of the network using a uniform distribution that generates value between [1,-1] this is true. Also, this set containing the initial value of the weights it's formally bounded since exists a ball with radius \textit{r} that include all the elements inside. 
	\begin{equation}
	X \subseteq \mathbb{R}^{n}  \textnormal{ bounded: } \exists  \textnormal{r >0  s.t S}  \in B(0,r)
	\end{equation}
	  Moreover $X$ is closed because its complementary set is open. This by definition (since $X$ is closed and bounded) prove that the set $X \subseteq \mathbb{R}^{n}$ we consider is compact. As mentioned in section \ref{activationFunction} each layer can use a \textit{sigmoid} bounded between (0,1) or \textit{tanH} bounded between (-1,+1) as activation function. Since every output layer is bounded the MSE is a continuous function.
	
	\item  \textbf{Differentiability}:  we are going to use \textit{sigmoid} (section \ref{sigmoid}) and \textit{hyperbolic tangent} (section \ref{tanH}) as activation functions. These function are continuous and twice differentiable with bounded Lipschitz continuous derivative. So \textit{Mean Squared Error} is a differentiable function since the network is a composition of continuously differentiable functions. Moreover, we know that the gradient of our loss function is Lipschitz continuous when we bound the set of the initialization of the layer's weight (which is our case as mention before). Indeed it is a product between bounded Lipschitz continuous functions. For this reason we decided to initialize the weight and the bias of our network with a uniform distribution taken in the range of two parameter.
	\item \textbf{Convexity}: all the functions used as activated function ($sigmoid$ and $tanH$) are not convex functions. Since our $MSE$ \textit{Loss Function} is obtained combining these not convex functions $MSE$ is not convex.
\end{itemize}

\subsection{Regularization}
 In machine learning, is used to insure a trade off between accuracy in training set and complexity of the model.
 We implemented and used two type of regularization, L1 and L2. They are implemented adding at the objective Loss Function a penalty term multiplied by a lambda parameter.
\begin{align*}
	{\mathbf{W} \in \mathbb{R}^n} {\ \mathit{L}(\mathbf{W}) + \lambda\Omega(\mathbf{W})}{}{}
	\label{eq:reg}
\end{align*}
 
\paragraph*{L1 regularization}
Usually named as Lasso regression it was defined as follow:
$\Omega(\textbf{W}) = \sum_{i=1}^{k} |w_i| = \|\textbf{W}\|_1$.
\paragraph*{L2 regularization}
Usually named as Ridge regression it was defined as follow:
$\Omega(\textbf{W}) = \sum_{i=1}^{k}w_i^2 = \|\textbf{W}\|_2^2$. 
 
 
%The first section of your report should contain a description of the problem and the methods that you plan to use.This is intended just as a brief recall, to introduce some notation and specify which variants of the methods you are planning to use exactly. Discuss the reasons behind the choices you make (the one you can make, that is, since several of them will be dictated by the statement of the project and cannot be questioned).Your target audience should be someone who is already sufficiently familiar with the content of the course. This is not the place to show your knowledge and repeat a large part of the theory: we are sure that you all can do that,1
%2 Structure of your report2given enough time, books, slides, and internet bandwidth. A more in-depth mathematical part is expected in the next stage.In case adapting the algorithm to your problem requires some further mathematical derivation (example: developingan exact line search for your problem, when possible, or adapting an algorithm to deal more efficiently with the special structure of your problem), you are supposed to discuss it here with all the necessary mathematical detail. You are advised to send us a version of this section by e-mail as soon as it is done, so that we can catch misunderstandings as soon as possible and minimize the amount of work wasted. Note that we do not want to see code at this point: that would be premature to produce (for you) and unnecessarily complicated to read (for us).