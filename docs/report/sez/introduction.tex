\section{Introduction}
At the beginning, we provide a short description of the problem. Next, we talk about the implemented method to find the gradient and the activation function used in the experiments. At the end, we provide some information about the used regularization method.
\subsection{Neural network}
Let M be a neural network with specific topology.
\\
The main goal of this project was to learn and develop three different optimization methods for M.
We exploit:
\begin{itemize}
	\item Standard momentum descent approach;
	\item Algorithm of the class of limited-memory quasi-Newton methods for L2 regularization;
	\item Algorithm of the class of bundle methods for L1 regularization;
\end{itemize}
\subsection{Back-propagation}
The back-propagation algorithm can be divided in two equally important part:
\begin{itemize}
	\item Compute the network's gradient;
	\item Use the knowledge of the gradient to do the next step depending on the optimizer chosen;
\end{itemize}
\subsection{Activation function}
The activation function of a node defines the output of that node given an input or set of inputs. 
Desirable properties of this function can be:
\begin{itemize}
	\item Nonlinear;
	\item Range;
	\item Continuously differentiable;
	\item Monotonic;
	\item Smooth functions with a monotonic derivative;
	\item Approximates identity near the origin;
\end{itemize}

For the aim of our project, we chose to use two different activation function:
\begin{itemize}
	\label{sigmoid}
	\item Sigmoid (or standard logistic function):
	\begin{itemize}
		\item It is defined between (0,1); 		
			\begin{align*}
			&f(x) = \sigma(x) = \frac{1}{1 + e^{-x}} \\
			&f'(x) = \sigma'(x) = f(x)(1 - f(x)),
			\end{align*} 
	\end{itemize}
	\item TanH;
	\label{tanH}
	\begin{itemize}
		\item It is defined between (-1,1); 		
		\begin{align*}
		&f(x) = \sigma(x) = \frac{e^{x}-e^{-x}}{e^{x} + e^{-x}} \\
		&f'(x) = \sigma'(x) = 1 - f(x)^{2},
		\end{align*} 
	\end{itemize}
\end{itemize}
\subsection{Loss Function}
The \textit{Loss Function} is a function used to evaluate the performance of a model, it receives a vector values $y$ computed by passing input data to the model and compare it with the desired vector values $\widehat{y}$.
Moreover the train phase of a supervised machine learning algorithm can be seen as an optimization (in our case minimization) of the \textit{Loss Function} $f(x)$ by altering $x$.   

There are several \textit{Loss Function} used in machine learning algorithms but we are going to focus on the \textit{Mean Squared Error} (MSE). This is obtained by the formula: 	
\begin{equation}
MSE = \frac{1}{n} \sum_{i=1}^n (\widehat{y}-y)_{i}^2
\end{equation}
where $n$ represents the number of sample input data we passed into in the model. Since purpose of neural networks is to build models that fits data, we want to minimize the \textit{Loss Function} in order to have good prediction on unseen data. This minimization process is done through optimization algorithms but to minimize the \textit{Loss Function} it must have certain properties.	

\subsubsection{Loss Function properties}
In an optimization problem given $X$ any set and $f: X \rightarrow \mathbb{R}$ any function we want
\begin{equation}
(P) \quad f_{*} = min \{f(x) : x \in X\}
\end{equation}
where X is the feasible region, f is the objective function and, $v(P) = f_{*}$ is the optimal value. In our case $X \subseteq \mathbb{R}^{n}$ and we want to be sure that exist an optimal solution.

So we want to find any optimal solution: $x_{*} \in X  \textnormal{ such that } f(x_{*}) = f_{*}$ but this can be impossible for many reasons. For the \textit{Weierstrass} theorem to ensure that our function has an optimal solution we need that $X \subseteq \mathbb{R}^{n}$ is compact and $f$ is continuous (or lower semi-continuous) and differentiable. 

\begin{itemize}
	\item \textbf{Continuity}: \textit{Loss Function} is a two variables function, $\widehat{y}$ and $y$. A function $f$ having two variables is Lipschitz continuous on its domain if $\exists L>0$ such that 
	\begin{equation}
	\parallel f(x_{1},y_{1}) - f(x_{2}, y_{2}) \parallel \leq L(\parallel x_{1}-x_{2}\parallel +  \parallel y_{1}-y_{2}\parallel) \quad \forall (x_{1},y_{1}),(x_{2},y_{2}) \in \textnormal{domain} f,  
	\end{equation} 
	neural networks are a series of function composition: 
	\begin{equation}
	h(\vec{x}) = \phi_{k}(b_{k} + \sum_{j}w_{kj} \phi_{j}(b_{j} + \sum_{i}w_{ji}\vec{x}))
	\end{equation}
	where $\vec{x}$ is the input vector and $\phi_{i}$ is an activation function. Since the activation functions used in the network are Lipschitz functions and the composition of a $k_{1}$-Lipschitz function, $f_{1}$, with a $k_{2}$-Lipschitz function, $f_{2}$, is a $k_{1}k_{2}$-Lipschitz function, the \textit{Loss Function} is a Lipschitz function. Moreover, as shown in \cite{lipschitzContinuity}, using $L(f)$ as a constant of some function $f$ we can compute an upper bound on the Lipschitz constant for the entire feed-forward neural network. 
	\item  \textbf{Differentiability}:  we are going to use \textit{sigmoid} (sez \ref{sigmoid}) and \textit{hyperbolic tangent} (sez \ref{tanH}) as activation functions. These function are continuous and twice differentiable with bounded Lipschitz continuous derivative. So \textit{Mean Squared Error} is a differentiable function since the network is a composition of continuously differentiable functions.
	\item \textbf{Convexity}: all the functions used as activated function ($sigmoid$ and $tanH$) are not convex functions. Since our $MSE$ \textit{Loss Function} is obtained combining these not convex functions $MSE$ is not convex.
\end{itemize}
\subsection{Properties}
\subsection{Regularization}
 In machine learning, is used to insure a trade off between accuracy in training set and complexity of the model.
 We implemented and used two type of regularization, L1 and L2. They are implemented adding at the objective Loss Function a penalty term multiplied by a lambda parameter.
\begin{align*}
	{\mathbf{W} \in \mathbb{R}^n} {\ \mathit{L}(\mathbf{W}) + \lambda\Omega(\mathbf{W})}{}{}
	\label{eq:reg}
\end{align*}
 
\paragraph*{L1 regularization}
Usually named as Lasso regression it was defined as follow:
$\Omega(\textbf{W}) = \sum_{i=1}^{k} |w_i| = \|\textbf{W}\|_1$.
\paragraph*{L2 regularization}
Usually named as Ridge regression it was defined as follow:
$\Omega(\textbf{W}) = \sum_{i=1}^{k}w_i^2 = \|\textbf{W}\|_2^2$. 
 
 
%The first section of your report should contain a description of the problem and the methods that you plan to use.This is intended just as a brief recall, to introduce some notation and specify which variants of the methods you are planning to use exactly. Discuss the reasons behind the choices you make (the one you can make, that is, since several of them will be dictated by the statement of the project and cannot be questioned).Your target audience should be someone who is already sufficiently familiar with the content of the course. This is not the place to show your knowledge and repeat a large part of the theory: we are sure that you all can do that,1
%2 Structure of your report2given enough time, books, slides, and internet bandwidth. A more in-depth mathematical part is expected in the next stage.In case adapting the algorithm to your problem requires some further mathematical derivation (example: developingan exact line search for your problem, when possible, or adapting an algorithm to deal more efficiently with the special structure of your problem), you are supposed to discuss it here with all the necessary mathematical detail. You are advised to send us a version of this section by e-mail as soon as it is done, so that we can catch misunderstandings as soon as possible and minimize the amount of work wasted. Note that we do not want to see code at this point: that would be premature to produce (for you) and unnecessarily complicated to read (for us).